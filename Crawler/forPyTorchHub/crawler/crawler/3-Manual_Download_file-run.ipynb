{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet \n",
      "DCGAN on FashionGen \n",
      "Deeplabv3-ResNet101 \n",
      "Densenet \n",
      "FCN-ResNet101 \n",
      "GoogLeNet \n",
      "HarDNet \n",
      "Inception_v3 \n",
      "MobileNet v2 \n",
      "Progressive Growing of GANs (PGAN) \n",
      "ProxylessNAS \n",
      "PyTorch-Transformers \n",
      "ResNet \n",
      "ResNext \n",
      "ResNext WSL \n",
      "RoBERTa ----empty-----\n",
      "Semi-supervised and semi-weakly supervised ImageNet Models \n",
      "ShuffleNet v2 \n",
      "SqueezeNet \n",
      "SSD \n",
      "Tacotron 2 \n",
      "Transformer (NMT) \n",
      "U-Net for brain MRI \n",
      "vgg-nets \n",
      "WaveGlow \n",
      "Wide ResNet \n"
     ]
    }
   ],
   "source": [
    "import torch, os, shutil\n",
    "\n",
    "for f in os.listdir(r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"):\n",
    "    if \".md\" in f:\n",
    "        continue\n",
    "    hehe = \"downloaded\"\n",
    "    hehe = \"----empty-----\" if \"torch\" not in os.listdir(os.path.join(r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\", f)) else \"\"\n",
    "        \n",
    "    print(f, hehe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/archive/master.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.utils.data' has no attribute 'IterableDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-060e30fc1f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-060e30fc1f25>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Transformer (NMT)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0men2fr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pytorch/fairseq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transformer.wmt14.en-fr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'moses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbpe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'subword_nmt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0men2de\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pytorch/fairseq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transformer.wmt19.en-de.single_model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'moses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbpe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fastbpe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0men2de\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pytorch/fairseq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transformer.wmt19.en-de.single_model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'moses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbpe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fastbpe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(github, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepo_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mhub_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepo_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master/hubconf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBPEHubInterface\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbpe\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizerHubInterface\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtokenizer\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMODEL_REGISTRY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fairseq.progress_bar'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterions\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\criterions\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfairseq_criterion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFairseqCriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLegacyFairseqCriterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\criterions\\fairseq_criterion.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msafe_round\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgelu_accurate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiheadAttention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\modules\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0madaptive_softmax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaptiveSoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbeamable_mm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeamableMM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcharacter_token_embedder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCharacterTokenEmbedder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconv_tbc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvTBC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\modules\\character_token_embedder.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mCHAR_PAD_IDX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTruncatedDictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfairseq_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFairseqDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFairseqIterableDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase_wrapper_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseWrapperDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\pytorch_fairseq_master\\fairseq\\data\\fairseq_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFairseqIterableDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEpochListening\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \"\"\"For datasets that need to be read sequentially, usually because the data\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mis\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mstreamed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0motherwise\u001b[0m \u001b[0mcan\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmanipulated\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mmachine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.utils.data' has no attribute 'IterableDataset'"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Transformer (NMT)\"\n",
    "    ## \n",
    "    en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n",
    "    en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    de2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    en2ru = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    ru2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Progressive Growing of GANs (PGAN)\"\n",
    "    ## \n",
    "    use_gpu = True if torch.cuda.is_available() else False\n",
    "    model1 = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                           'PGAN', model_name='celebAHQ-512',\n",
    "                           pretrained=True, useGPU=use_gpu)\n",
    "    model2 = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                           'PGAN', model_name='celebAHQ-256',\n",
    "                           pretrained=True, useGPU=use_gpu)\n",
    "    model3 = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                           'PGAN', model_name='DTD',\n",
    "                           pretrained=True, useGPU=use_gpu)\n",
    "    model4 = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                           'PGAN', model_name='celeba',\n",
    "                           pretrained=True, useGPU=use_gpu)\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\v0.4.2.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 46827520/46827520 [00:01<00:00, 26560666.95it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet34-333f7ec4.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 87306240/87306240 [00:01<00:00, 87182646.67it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet50-19c8e357.pth\n",
      "100%|█████████████████████████████████████████████████████████████| 102502400/102502400 [00:00<00:00, 117078160.72it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet101-5d3b4d8f.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 178728960/178728960 [00:02<00:00, 72547244.60it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet152-b121ed2d.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 241530880/241530880 [00:10<00:00, 23785343.56it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"ResNet\"\n",
    "    ## \n",
    "    model1 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet18', pretrained=True)\n",
    "    model2 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet34', pretrained=True)\n",
    "    model3 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet50', pretrained=True)\n",
    "    model4 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet101', pretrained=True)\n",
    "    model5 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet152', pretrained=True)\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    model4.eval()\n",
    "    model5.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/archive/master.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\master.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 46827520/46827520 [00:02<00:00, 20963117.30it/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet18-118f1556.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnet18-118f1556.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 46811375/46811375 [00:01<00:00, 25806434.91it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet50-19c8e357.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 102502400/102502400 [00:04<00:00, 21366903.73it/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet50-16a12f1b.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnet50-16a12f1b.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 102480594/102480594 [00:03<00:00, 27826175.01it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext50_32x4-72679e44.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnext50_32x4-72679e44.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 100428550/100428550 [00:03<00:00, 29301962.34it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x4-3f87e46b.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnext101_32x4-3f87e46b.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 177341913/177341913 [00:05<00:00, 30858281.95it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x8-b4712904.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnext101_32x8-b4712904.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 356056638/356056638 [00:25<00:00, 13991023.23it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x16-f3559a9c.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_weakly_supervised_resnext101_32x16-f3559a9c.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 777518664/777518664 [00:23<00:00, 32830369.60it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet18-d92f0530.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnet18-d92f0530.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 46811375/46811375 [00:01<00:00, 25099496.47it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet50-08389792.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnet50-08389792.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 102480594/102480594 [00:03<00:00, 29443665.58it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext50_32x4-ddb3e555.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnext50_32x4-ddb3e555.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 100428550/100428550 [00:03<00:00, 28698215.24it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x4-dc43570a.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnext101_32x4-dc43570a.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 177341913/177341913 [00:05<00:00, 30877208.26it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x8-2cfe2f8b.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnext101_32x8-2cfe2f8b.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 356056638/356056638 [00:11<00:00, 31558383.76it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x16-15fffa57.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\semi_supervised_resnext101_32x16-15fffa57.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 777518664/777518664 [00:24<00:00, 32098287.18it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Semi-supervised and semi-weakly supervised ImageNet Models\"\n",
    "    ## \n",
    "    # === SEMI-WEAKLY SUPERVISED MODELSP RETRAINED WITH 940 HASHTAGGED PUBLIC CONTENT === \n",
    "    model1 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl')\n",
    "    model2 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet50_swsl')\n",
    "    model3 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_swsl')\n",
    "    model4 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x4d_swsl')\n",
    "    model5 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x8d_swsl')\n",
    "    model6 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x16d_swsl')\n",
    "    # ================= SEMI-SUPERVISED MODELS PRETRAINED WITH YFCC100M ==================\n",
    "    model7 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_ssl')\n",
    "    model8 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet50_ssl')\n",
    "    model9 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_ssl')\n",
    "    model10 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x4d_ssl')\n",
    "    model11 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x8d_ssl')\n",
    "    model12 = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x16d_ssl')\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    model4.eval()\n",
    "    model5.eval()\n",
    "    model6.eval()\n",
    "    model7.eval()\n",
    "    model8.eval()\n",
    "    model9.eval()\n",
    "    model10.eval()\n",
    "    model11.eval()\n",
    "    model12.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\v0.4.2.zip\n",
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\shufflenetv2_x1-5666bf0f80.pth\n",
      "100%|██████████████████████████████████████████████████████████████████| 9218294/9218294 [00:00<00:00, 37341396.41it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"ShuffleNet v2\"\n",
    "    ## \n",
    "    model = torch.hub.load('pytorch/vision:v0.4.2', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "    model.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\v0.4.2.zip\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\squeezenet1_0-a815701f.pth\n",
      "100%|██████████████████████████████████████████████████████████████████| 5017600/5017600 [00:00<00:00, 19164445.27it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\squeezenet1_1-f364aa15.pth\n",
      "100%|██████████████████████████████████████████████████████████████████| 4966400/4966400 [00:00<00:00, 18890876.22it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"SqueezeNet\"\n",
    "    ## \n",
    "    model1 = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_0', pretrained=True)\n",
    "# or\n",
    "    model2 = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_1', pretrained=True)\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/archive/torchhub.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\torchhub.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\resnet50-19c8e357.pth\n",
      "100%|████████████████████████████████████████████████████████████████| 102502400/102502400 [06:24<00:00, 266677.59it/s]\n",
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/1/files/nvidia_ssdpyt_fp32_20190225.pt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-faf3d9416b4f>\", line 13, in <module>\n",
      "    test()\n",
      "  File \"<ipython-input-2-faf3d9416b4f>\", line 7, in test\n",
      "    ssd_model1 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp32')\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\torch\\hub.py\", line 341, in load\n",
      "    model = entry(*args, **kwargs)\n",
      "  File \"C:\\Users\\xmk233/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub/hubconf.py\", line 370, in nvidia_ssd\n",
      "    ckpt_file = _download_checkpoint(checkpoint, force_reload)\n",
      "  File \"C:\\Users\\xmk233/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub/hubconf.py\", line 46, in _download_checkpoint\n",
      "    urllib.request.urlretrieve(checkpoint, ckpt_file)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\urllib\\request.py\", line 277, in urlretrieve\n",
      "    block = fp.read(bs)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\http\\client.py\", line 449, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\http\\client.py\", line 493, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\ssl.py\", line 1012, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\ssl.py\", line 874, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\ssl.py\", line 631, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\xmk233\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"SSD\"\n",
    "    ## \n",
    "    ssd_model1 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp32')\n",
    "    ssd_model2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp16')\n",
    "    ######\n",
    "#     shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Tacotron 2\"\n",
    "    ## \n",
    "#     tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2')\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### failed. AttributeError: module 'torch.utils.data' has no attribute 'IterableDataset'\n",
    "### find full list in https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_fairseq_translation.ipynb#scrollTo=Eew9B2L6qKWO\n",
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Transformer (NMT)\"\n",
    "    ## \n",
    "    en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n",
    "    en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    de2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    en2ru = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "    ru2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Wed, 08 Apr 2020 02:51:13 GMT\n",
      "Content-Type: application/x-tar\n",
      "Content-Length: 2316140317\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=dda68f78794c29444cdbcc9871f9dc3e91586314272; expires=Fri, 08-May-20 02:51:12 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: hthihJjqOnQ8skQxD2uxUsHh34ePNnc5twwjUz32phC3PdqTrM9605L14pJocElcVz+BWId6GDI=\n",
      "x-amz-request-id: 43656FE845696B5B\n",
      "Last-Modified: Thu, 24 Jan 2019 20:05:21 GMT\n",
      "ETag: \"9bb188053e935f6f588088b734859056-277\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-version-id: swUklLew0TotyB0tpa6S2atRcUhUPNXx\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af6dec3e73d1-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:14 GMT\n",
      "Content-Type: application/x-tar\n",
      "Content-Length: 2193287384\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=d8a3972c339fd34fc21225429782e52f31586314273; expires=Fri, 08-May-20 02:51:13 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: /cmrjdOXJKrClLY9kJM5W9CM0xfZ/dfteAK5mv1kzwZLXmaiPfgZCvBIvv9nTYAbLRRqXKuXSXs=\n",
      "x-amz-request-id: 21DD4DBA8DD340F7\n",
      "Last-Modified: Thu, 24 Jan 2019 20:12:05 GMT\n",
      "ETag: \"7a4b28889aabaec5f51baf58a5686fc8-262\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-version-id: P3myd5FsQ1PTud1SXntN9Fpfr7KmlDnN\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af722fd073b5-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:14 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 13605842351\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=d77216b8855488aac6acbc8bb6f6ebffc1586314274; expires=Fri, 08-May-20 02:51:14 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: 1OlvYCn1r+chG1lhPLZR6SrQ3O9wmGBUxiKsmwjb42F4HcjYLLP1mf1LJZ5XxwlxjYkVsRotVuU=\n",
      "x-amz-request-id: 2D614847B5B3821A\n",
      "Last-Modified: Wed, 12 Jun 2019 21:57:01 GMT\n",
      "ETag: \"84a705916dbab95f19779a236f34a095-866\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1560375889/ctime:1560374975/gid:1185200010/gname:myleott/md5:cf0f1a1b28abe5873fc441787a45451e/mode:33204/mtime:1560374975/uid:1185200010/uname:myleott\n",
      "x-amz-version-id: rtSdcmWyFlY6wUrEdrha.yOrkcTf4aov\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af765fd2e0c6-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:16 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 11946275315\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=db59102df3aa925dca579cdd69320adc71586314276; expires=Fri, 08-May-20 02:51:16 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: dFtWd+z7yazKNvr9NeR4kglz1w4S6xR+xAnUbzgCh2ZSt1s0a/J9l8YmuHmOqXQ4UiPCMv2GpPI=\n",
      "x-amz-request-id: 5234565265D000B5\n",
      "Last-Modified: Thu, 01 Aug 2019 23:05:05 GMT\n",
      "ETag: \"452c6068c25b420c974a7f995e96ab88-760\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564699755/ctime:1564700443/gid:1185300604/gname:nng/md5:2e04881e94670a3cab7c7de2c6375465/mode:33204/mtime:1564700443/uid:1185300604/uname:nng\n",
      "x-amz-version-id: W5Sv1Ah0VmvTKfp1HzrxKGaNrAuZk.WJ\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af835c58eaa2-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:17 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 12148138544\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=dae27b94fccf882c302ed6910a6c0a7761586314276; expires=Fri, 08-May-20 02:51:16 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: d7zQvXkJUJdW+f4MeRu6ygqJNS4fH7c/ftGqHou/Q2dvmq5Z3P+49t33cPoZDs7SF6cLRhe/zsU=\n",
      "x-amz-request-id: 627F2379FD785B61\n",
      "Last-Modified: Thu, 01 Aug 2019 23:05:06 GMT\n",
      "ETag: \"f7b051867d03c01d9360d0e611867696-773\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564699755/ctime:1564700508/gid:1185300604/gname:nng/md5:e36f05ce5fd3a6eef2f121f9f8d70e74/mode:33204/mtime:1564700508/uid:1185300604/uname:nng\n",
      "x-amz-version-id: UNUvh8d_U32QhJCMuuSLb42THpIHUI6G\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af8688127451-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:17 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 11958904958\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=de4fe509b7075c4c5ef0a3b62709d52471586314277; expires=Fri, 08-May-20 02:51:17 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: ORiz+1m30yPu3SQsrJzppzEkdBYh7pXbQpvTRFqoU4tgFr4Sg6Ph+hc1fJnUxIA60zkYZb2bSDY=\n",
      "x-amz-request-id: D82898EE7A6C42C7\n",
      "Last-Modified: Thu, 01 Aug 2019 23:05:06 GMT\n",
      "ETag: \"e2383b2d6bb8fa5683d1b329f4a0f3cc-761\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564699755/ctime:1564700428/gid:1185300604/gname:nng/md5:a41fbfeb0032352de6de612a560d6e76/mode:33204/mtime:1564700428/uid:1185300604/uname:nng\n",
      "x-amz-version-id: DMYQkceR_PTbLfA2ZKP0cfczmPBwfpvh\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af8a4f51f0bd-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:18 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 12161762203\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=dd7651eacb5529c3630c9da60546e54201586314278; expires=Fri, 08-May-20 02:51:18 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: kHJdho8L/SOKnyo4xh63ymbwWBpVzZiOqQL9VQCcfvlrBHI0H34y9ovJ7h/OwVrGhjKB28iv8mI=\n",
      "x-amz-request-id: 8358C1D0D447C2AB\n",
      "Last-Modified: Thu, 01 Aug 2019 23:05:07 GMT\n",
      "ETag: \"3d99dccd9db579935abc1ff788b46c31-774\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564699755/ctime:1564700460/gid:1185300604/gname:nng/md5:edbda64c81c3d0985944bb08b1c3a1f9/mode:33204/mtime:1564700460/uid:1185300604/uname:nng\n",
      "x-amz-version-id: mRO95yAQgSXI.jQbeVAPopUXdo6zi4C7\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af8d9b5074b7-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:19 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 2988854245\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=d315ab04e52a6579ff29437f3b9d3c2cd1586314278; expires=Fri, 08-May-20 02:51:18 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: bJ2EE2xpA8PHCsLC4gDfAu0VdH3qFmHhV7Z4QI5QGS+ONrmsQgowup79BCQ3ZZRZIJQxiApLUJE=\n",
      "x-amz-request-id: 2423B6574A39C10D\n",
      "Last-Modified: Fri, 02 Aug 2019 12:59:10 GMT\n",
      "ETag: \"416a97154b19c8245b8b59ca612fa60c-191\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564750180/ctime:1564750513/gid:1185200010/gname:myleott/md5:0824468a245461ae3fc137f8270c01c8/mode:33204/mtime:1564750513/uid:1185200010/uname:myleott\n",
      "x-amz-version-id: uuKiwIiFIWwSQ0JOdiQFvSv6BueeFS76\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af915e98cf1c-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:19 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 3037373614\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=daae65023385feb3a718375c2405fc8f01586314279; expires=Fri, 08-May-20 02:51:19 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: Z2wjkqpyKJ8k0DwMCIgIIguhdnGf6z9j0vbirt9KOFoWZ/8tg1WMz+ke4vw6GZHH4sBfG6bpv6U=\n",
      "x-amz-request-id: E643DF69B837676A\n",
      "Last-Modified: Fri, 02 Aug 2019 13:06:24 GMT\n",
      "ETag: \"e435c6818d114f80b6ff5af1543316d7-194\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564751153/ctime:1564751162/gid:1185200010/gname:myleott/md5:85df3155a8bc9016e0e1fbc1bf962049/mode:33204/mtime:1564751162/uid:1185200010/uname:myleott\n",
      "x-amz-version-id: cg.vANJ_ktsMas8FU0RA19GbCiYxV6bm\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af94ac0bcef8-IAD\n",
      "\n",
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:20 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 2992273886\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=df2dc700fc957bd34067c087d16909f3f1586314279; expires=Fri, 08-May-20 02:51:19 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: SsD6V8lRUU1Yan/a6ZfMAIIAwOA/Cg2+iY3PM4B6Wgy8E32ZrnJfYJ82kig/lRzSF87Tb6Bj+0Y=\n",
      "x-amz-request-id: 82EEF03091857AEA\n",
      "Last-Modified: Fri, 02 Aug 2019 12:56:22 GMT\n",
      "ETag: \"66d62ee383edae097c2fc81e781e1e86-191\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564750491/ctime:1564750466/gid:1185200010/gname:myleott/md5:fbd5b70052a464972dba5479c96003f7/mode:33204/mtime:1564750466/uid:1185200010/uname:myleott\n",
      "x-amz-version-id: VZ4aDlKySV5kJAV5I1JdkyRGq6OVo21i\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af97c8e2cec0-IAD\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date: Wed, 08 Apr 2020 02:51:20 GMT\n",
      "Content-Type: application/gzip\n",
      "Content-Length: 3041223502\n",
      "Connection: close\n",
      "Set-Cookie: __cfduid=d2f550ee6961a3f192ded7ce10cff57d61586314280; expires=Fri, 08-May-20 02:51:20 GMT; path=/; domain=.fbaipublicfiles.com; HttpOnly; SameSite=Lax\n",
      "x-amz-id-2: Vc7xyB95AeT0U0WPqKV0hVui0dbIoSQEU849TcfIvga2c1pBB+vkigPO6flkwyWox3ITuxwex+w=\n",
      "x-amz-request-id: 88D822AEEF11DF74\n",
      "Last-Modified: Fri, 02 Aug 2019 13:06:38 GMT\n",
      "ETag: \"bab86e8dcf0af256b209d661e6bdf4d1-194\"\n",
      "x-amz-server-side-encryption: AES256\n",
      "x-amz-meta-s3cmd-attrs: atime:1564751164/ctime:1564751173/gid:1185200010/gname:myleott/md5:8eebabc0cf33be128f9a5c9700808fbc/mode:33204/mtime:1564751173/uid:1185200010/uname:myleott\n",
      "x-amz-version-id: thrYV5H4sEXwyiV4CQShpPXdne1ISd5F\n",
      "Accept-Ranges: bytes\n",
      "CF-Cache-Status: DYNAMIC\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Server: cloudflare\n",
      "CF-RAY: 5808af9bcbbc749f-IAD\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2316140317,\n",
       " 2193287384,\n",
       " 13605842351,\n",
       " 11946275315,\n",
       " 12148138544,\n",
       " 11958904958,\n",
       " 12161762203,\n",
       " 2988854245,\n",
       " 3037373614,\n",
       " 2992273886,\n",
       " 3041223502]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request as urllib2\n",
    "def getRemoteFileSize(url, proxy=None):\n",
    "    \"\"\" 通过content-length头获取远程文件大小\n",
    "        url - 目标文件URL\n",
    "        proxy - 代理  \"\"\"\n",
    "    opener = urllib2.build_opener()\n",
    "    if proxy:\n",
    "        if url.lower().startswith('https://'):\n",
    "            opener.add_handler(urllib2.ProxyHandler({'https' : proxy}))\n",
    "        else:\n",
    "            opener.add_handler(urllib2.ProxyHandler({'http' : proxy}))\n",
    "    try:\n",
    "        request = urllib2.Request(url)\n",
    "        request.get_method = lambda: 'HEAD'\n",
    "        response = opener.open(request)\n",
    "        response.read()\n",
    "    except Exception:\n",
    "        return 0\n",
    "    else:\n",
    "        print(response.headers)\n",
    "        fileSize = dict(response.headers).get('Content-Length', 0)\n",
    "        return int(fileSize)\n",
    "size_list = [\n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt18.en-de.ensemble.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.ensemble.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.ensemble.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.ensemble.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.ensemble.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.single_model.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz\"), \n",
    "    getRemoteFileSize(\"https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.single_model.tar.gz\"),\n",
    "]\n",
    "size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/archive/master.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\master.zip\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\unet-e012d006.pt\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"U-Net for brain MRI\"\n",
    "    ## \n",
    "    model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                           in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\v0.4.2.zip\n",
      "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg11-bbd30ac9.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 531456000/531456000 [00:06<00:00, 82685106.58it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg11_bn-6002323d.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 531503671/531503671 [00:06<00:00, 87522888.79it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg13-c768596a.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 532194478/532194478 [00:10<00:00, 52783651.80it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg13_bn-abd245e5.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 532246301/532246301 [00:07<00:00, 72619157.02it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 553433881/553433881 [00:24<00:00, 22783863.58it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg16_bn-6c64b313.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 553507836/553507836 [00:07<00:00, 78034659.66it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 574673361/574673361 [00:28<00:00, 20414158.72it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\vgg19_bn-c79401a0.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 574769405/574769405 [00:07<00:00, 77002401.54it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"vgg-nets\"\n",
    "    ## \n",
    "    model1 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg11', pretrained=True)\n",
    "    model2 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg11_bn', pretrained=True)\n",
    "    model3 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg13', pretrained=True)\n",
    "    model4 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg13_bn', pretrained=True)\n",
    "    model5 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg16', pretrained=True)\n",
    "    model6 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg16_bn', pretrained=True)\n",
    "    model7 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg19', pretrained=True)\n",
    "    model8 = torch.hub.load('pytorch/vision:v0.4.2', 'vgg19_bn', pretrained=True)\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    model4.eval()\n",
    "    model5.eval()\n",
    "    model6.eval()\n",
    "    model7.eval()\n",
    "    model8.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"WaveGlow\"\n",
    "    ## \n",
    "#     waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
    "\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to C:\\Users\\xmk233/.cache\\torch\\hub\\v0.4.2.zip\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\wide_resnet50_2-95faca4d.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 138223492/138223492 [00:02<00:00, 49022316.36it/s]\n",
      "Using cache found in C:\\Users\\xmk233/.cache\\torch\\hub\\pytorch_vision_v0.4.2\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth\" to C:\\Users\\xmk233/.cache\\torch\\checkpoints\\wide_resnet101_2-32ee1156.pth\n",
      "100%|██████████████████████████████████████████████████████████████| 254695146/254695146 [00:05<00:00, 47968868.93it/s]\n"
     ]
    }
   ],
   "source": [
    "FROM_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\"\n",
    "FILE_PATH = r\"J:\\ModelStoreData\\PyTorchHub\\2020-01-07\\files\"\n",
    "def test():\n",
    "    ## \n",
    "    model_name = \"Wide ResNet\"\n",
    "    ## \n",
    "    # load WRN-50-2:\n",
    "    model1 = torch.hub.load('pytorch/vision:v0.4.2', 'wide_resnet50_2', pretrained=True)\n",
    "    # or WRN-101-2\n",
    "    model2 = torch.hub.load('pytorch/vision:v0.4.2', 'wide_resnet101_2', pretrained=True)\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    ######\n",
    "    shutil.move(FROM_DIR, os.path.join(FILE_PATH, model_name, \"torch\"))\n",
    "    return\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test('bert-base-cased')\n",
      "test('bert-base-german-dbmdz-cased')\n",
      "test('bert-base-german-dbmdz-uncased')\n",
      "test('bert-base-japanese')\n",
      "test('bert-base-japanese-char')\n",
      "test('bert-base-japanese-char-whole-word-masking')\n",
      "test('bert-base-japanese-whole-word-masking')\n",
      "test('bert-base-multilingual-cased')\n",
      "test('bert-base-uncased')\n",
      "test('bert-large-cased')\n",
      "test('bert-large-cased-whole-word-masking')\n",
      "test('bert-large-cased-whole-word-masking-finetuned-squad')\n",
      "test('bert-large-uncased')\n",
      "test('bert-large-uncased-whole-word-masking')\n",
      "test('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
      "test('distilbert-base-german-cased (1/2 data to pretrained)')\n",
      "test('distilbert-base-multilingual-cased')\n",
      "test('distilbert-base-uncased')\n",
      "test('distilbert-base-uncased-distilled-squad')\n",
      "test('gpt2')\n",
      "test('gpt2-large')\n",
      "test('gpt2-medium')\n",
      "test('gpt2-xl')\n",
      "test('openai-gpt')\n",
      "test('roberta-base')\n",
      "test('roberta-base-openai-detector')\n",
      "test('roberta-large')\n",
      "test('roberta-large-openai-detector')\n",
      "test('transfo-xl-wt103')\n",
      "test('xlm-clm-ende-1024')\n",
      "test('xlm-clm-enfr-1024')\n",
      "test('xlm-mlm-ende-1024')\n",
      "test('xlm-mlm-enfr-1024')\n",
      "test('xlm-mlm-tlm-xnli15-1024')\n",
      "test('xlm-mlm-xnli15-1024')\n",
      "test('xlnet-base-cased')\n",
      "test('xlnet-large-cased')\n"
     ]
    }
   ],
   "source": [
    "def for_transformer():\n",
    "    with open(\"huggingface_transformer.txt\", \"r\") as ht:\n",
    "        contents = ht.readlines()\n",
    "    contents.sort()\n",
    "    for content in contents:\n",
    "        _ = content.strip()\n",
    "        if not _ == \"\":\n",
    "            print(\"test(\\'{}\\')\".format(_))\n",
    "\n",
    "for_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the downloading of transformers, see 4-xxx.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-04-12 I want to know what extra models need to be downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test('bert-base-finnish-cased-v1')\n",
      "test('bert-base-cased-finetuned-mrpc')\n",
      "test('distilbert-base-cased-distilled-squad')\n",
      "test('roberta-large-mnli')\n",
      "test('xlm-mlm-enro-1024')\n",
      "test('distilgpt2')\n",
      "test('bert-base-finnish-uncased-v1')\n",
      "test('xlm-mlm-en-2048')\n",
      "test('bert-base-multilingual-uncased')\n",
      "test('bert-base-chinese')\n",
      "test('xlm-mlm-100-1280')\n",
      "test('distilroberta-base')\n",
      "test('distilbert-base-cased')\n",
      "test('xlm-mlm-17-1280')\n",
      "test('bert-base-dutch-cased')\n",
      "test('bert-base-german-cased')\n"
     ]
    }
   ],
   "source": [
    "def for_transformer_2020():\n",
    "    with open(\"huggingface_transformer.txt\", \"r\") as ht:\n",
    "        contents = ht.readlines()\n",
    "    with open(\"huggingface_transformer-2020_04_12.txt\", \"r\") as ht:\n",
    "        contents_2020 = ht.readlines()\n",
    "    contents = [i.strip() for i in contents]\n",
    "    contents.sort()\n",
    "    contents_2020 = [i.strip() for i in contents_2020]\n",
    "    contents_2020.sort()\n",
    "    \n",
    "    new_contents = set(contents_2020) - set(contents)\n",
    "    \n",
    "    for content in new_contents:\n",
    "        _ = content.strip()\n",
    "        if not _ == \"\":\n",
    "            print(\"test(\\'{}\\')\".format(_))\n",
    "#     for n in contents_2020:\n",
    "#         if n not in contents:\n",
    "#             print(n)\n",
    "#     print(\"\\n\")\n",
    "#     for n in contents:\n",
    "#         if n not in contents_2020:\n",
    "#             print(n)\n",
    "#     print(\"So those are the newly added ones in 2020 snapshot.\")\n",
    "for_transformer_2020()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
