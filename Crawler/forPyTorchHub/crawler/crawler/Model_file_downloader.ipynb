{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Automatic download~~\n",
    "* ~~Automatic downloading is very hard, because the situation is very diverse. We cannot find a unified way to download all of the modules.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, shutil, re\n",
    "from lxml import etree\n",
    "\n",
    "TARGET_DIR = r\"J:\\ModelStoreData\\PyTorchHub\\2019-07-30\\files\"\n",
    "CKPT_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\\checkpoints\"\n",
    "FILE_DIR = r\"J:\\ModelStoreData\\PyTorchHub\\2019-07-30\\files\"\n",
    "\n",
    "def download_all_of_the_modules():\n",
    "    def download_files(dir, repo, entrypoint):\n",
    "        torch.hub.set_dir(\n",
    "            os.path.join(dir)\n",
    "        )\n",
    "        try:\n",
    "            eval(\"torch.hub.load({}, '{}')\".format(repo, entrypoint.replace(\"'\", \"\")))  #, pretrained=True\n",
    "        except:\n",
    "            print(\"FAIL: torch.hub.load({}, '{}')...{}\".format(repo, entrypoint.replace(\"'\", \"\"), dir)) #, pretrained=True\n",
    "        finally:\n",
    "            ckpt_dir = CKPT_DIR\n",
    "            for ckpt in os.listdir(ckpt_dir):\n",
    "                shutil.move(\n",
    "                    os.path.join(ckpt_dir, ckpt),\n",
    "                    os.path.join(dir, ckpt)\n",
    "                )\n",
    "                #print(\"{} {} хорошо\".format(repo, entrypoint))\n",
    "\n",
    "    def find_repo_from_items(items):\n",
    "        for item in items:\n",
    "            if len(item.split(\"/\")) == 2:\n",
    "                return items.index(item)\n",
    "\n",
    "    file_dir = FILE_DIR\n",
    "    for module in os.listdir(file_dir):\n",
    "        module_dir = os.path.join(file_dir, module)\n",
    "        html_path = os.path.join(module_dir, \"webpage.html\")\n",
    "        with open(html_path, \"r\", encoding=\"utf-8\") as hp:\n",
    "            html = hp.read()\n",
    "        page_source = etree.HTML(html)\n",
    "        module_author = page_source.xpath('//p[@class=\"detail-lead\"]/text()')[0]\n",
    "        items = page_source.xpath(\"//code/span[@class='s']/text()\")\n",
    "        repo_index = find_repo_from_items(items)\n",
    "        repo = items[repo_index]\n",
    "        if (\"Pytorch Team\" in module_author) or (\"Facebook AI\" in module_author): ### Pytorch Team模型和Facebook AI模型：找//table/tbody/tr/td[1]\n",
    "            eps = page_source.xpath('//table/tbody/tr/td[1]/text()')\n",
    "        elif \"HuggingFace Team\" in module_author: ### HuggingFace Team模型： 在module description和 requirement之间的部分，找//code[@class=\"highlighter-rouge\"]/text()\n",
    "            _ = re.findall('<article class=\"pytorch-article\">([\\s\\S]*)<h3 id=\"requirements\">', html)[0]  #\n",
    "            eps = etree.HTML(_).xpath('//code[@class=\"highlighter-rouge\"]/text()')\n",
    "        else: ### NVIDIA, FAIR HDGAN, 以及个人发布的模型，都在这里处理了。\n",
    "            eps = [items[repo_index + 1]]\n",
    "        for ep in eps:\n",
    "            download_files(\n",
    "                os.path.join(TARGET_DIR, module),\n",
    "                repo,\n",
    "                ep\n",
    "            )\n",
    "\n",
    "download_all_of_the_modules()\n",
    "\n",
    "# def download_by_repo(dir, repo):\n",
    "#     torch.hub.set_dir(\n",
    "#         os.path.join(dir)\n",
    "#     )\n",
    "#     try:\n",
    "#         eps = eval(\"torch.hub.list({})\".format(repo))\n",
    "#         for ep in eps:\n",
    "#             eval(\"torch.hub.load({}, '{}', pretrained=True)\".format(repo, ep))\n",
    "#             ckpt_dir = r\"C:\\Users\\xmk233\\.cache\\torch\\checkpoints\"\n",
    "#             for ckpt in os.listdir(ckpt_dir):\n",
    "#                 shutil.move(\n",
    "#                     os.path.join(ckpt_dir, ckpt),\n",
    "#                     os.path.join(dir, ckpt)\n",
    "#                 )\n",
    "#                 print(\"хорошо\")\n",
    "#     except:\n",
    "#         pass\n",
    "#     finally:\n",
    "#         ckpt_dir = r\"C:\\Users\\xmk233\\.cache\\torch\\checkpoints\"\n",
    "#         for ckpt in os.listdir(ckpt_dir):\n",
    "#             shutil.move(\n",
    "#                 os.path.join(ckpt_dir, ckpt),\n",
    "#                 os.path.join(dir, ckpt)\n",
    "#             )\n",
    "#             print(\"хорошо\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Manually downloading~~\n",
    "* ~~we'd better use manual downloading.~~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, shutil, re\n",
    "from lxml import etree\n",
    "\n",
    "TARGET_DIR = r\"J:\\ModelStoreData\\PyTorchHub\\2019-07-30\\files\"\n",
    "CKPT_DIR = r\"C:\\Users\\xmk233\\.cache\\torch\\checkpoints\"\n",
    "FILE_DIR = r\"J:\\ModelStoreData\\PyTorchHub\\2019-07-30\\files\"\n",
    "\n",
    "def download_all_of_the_modules():\n",
    "    \n",
    "    def download_files(dir, repo, entrypoint):\n",
    "        torch.hub.set_dir(\n",
    "            os.path.join(dir)\n",
    "        )\n",
    "        try:\n",
    "            eval(\"torch.hub.load({}, '{}')\".format(repo, entrypoint.replace(\"'\", \"\")))  #, pretrained=True\n",
    "        except:\n",
    "            print(\"FAIL: torch.hub.load({}, '{}')...{}\".format(repo, entrypoint.replace(\"'\", \"\"), dir)) #, pretrained=True\n",
    "        finally:\n",
    "            ckpt_dir = CKPT_DIR\n",
    "            for ckpt in os.listdir(ckpt_dir):\n",
    "                shutil.move(\n",
    "                    os.path.join(ckpt_dir, ckpt),\n",
    "                    os.path.join(dir, ckpt)\n",
    "                )\n",
    "                #print(\"{} {} хорошо\".format(repo, entrypoint))\n",
    "\n",
    "    def find_repo_from_items(items):\n",
    "        for item in items:\n",
    "            if len(item.split(\"/\")) == 2:\n",
    "                return items.index(item)\n",
    "\n",
    "    file_dir = FILE_DIR\n",
    "    for module in os.listdir(file_dir):\n",
    "        module_dir = os.path.join(file_dir, module)\n",
    "        html_path = os.path.join(module_dir, \"webpage.html\")\n",
    "        with open(html_path, \"r\", encoding=\"utf-8\") as hp:\n",
    "            html = hp.read()\n",
    "        page_source = etree.HTML(html)\n",
    "        module_author = page_source.xpath('//p[@class=\"detail-lead\"]/text()')[0]\n",
    "        items = page_source.xpath(\"//code/span[@class='s']/text()\")\n",
    "        repo_index = find_repo_from_items(items)\n",
    "        repo = items[repo_index]\n",
    "        if (\"Pytorch Team\" in module_author) or (\"Facebook AI\" in module_author): ### Pytorch Team模型和Facebook AI模型：找//table/tbody/tr/td[1]\n",
    "            eps = page_source.xpath('//table/tbody/tr/td[1]/text()')\n",
    "        elif \"HuggingFace Team\" in module_author: ### HuggingFace Team模型： 在module description和 requirement之间的部分，找//code[@class=\"highlighter-rouge\"]/text()\n",
    "            _ = re.findall('<article class=\"pytorch-article\">([\\s\\S]*)<h3 id=\"requirements\">', html)[0]  #\n",
    "            eps = etree.HTML(_).xpath('//code[@class=\"highlighter-rouge\"]/text()')\n",
    "        else: ### NVIDIA, FAIR HDGAN, 以及个人发布的模型，都在这里处理了。\n",
    "            eps = [items[repo_index + 1]]\n",
    "        for ep in eps:\n",
    "            download_files(\n",
    "                os.path.join(TARGET_DIR, module),\n",
    "                repo,\n",
    "                ep\n",
    "            )\n",
    "\n",
    "download_all_of_the_modules()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
