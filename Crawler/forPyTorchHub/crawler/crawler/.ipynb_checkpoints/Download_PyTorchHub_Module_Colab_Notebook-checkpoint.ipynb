{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to run this on Colab. And then zip the files and download the .zip file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/content/Data\")\n",
    "\n",
    "## upload the html files to the Colab. Where is it: \"/content\"\n",
    "\n",
    "!unzip /content/2019-07-30.zip -d /content/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### download the modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, shutil, re, time, json\n",
    "from lxml import etree\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = r\"/content/Data/\"\n",
    "TARGET_DIR = os.path.join(DATA_DIR, \"files\")\n",
    "CKPT_DIR = r\"/root/.cache/torch/checkpoints\"\n",
    "FILE_DIR = TARGET_DIR\n",
    "PYTORCH_TRANSFORMER_DIR = r\"/root/.cache/torch/pytorch_transformers\"\n",
    "record_file_path = os.path.join(DATA_DIR, \"record.json\")\n",
    "failed_file_path = os.path.join(DATA_DIR, \"failed_modules.json\")\n",
    "\n",
    "def download_all_of_the_modules():\n",
    "    module_info = {}\n",
    "\n",
    "    def download_files(module, ckpt_dir, dir, repo, entrypoint, *args, **kargs):\n",
    "        entrypoint = entrypoint.replace(\"'\", \"\")\n",
    "        torch.hub.set_dir(\n",
    "            os.path.join(dir)\n",
    "        )\n",
    "\n",
    "        print(\"\\n\\n\\n\\n\\n {}, {}, {}\".format(repo, entrypoint, dir))\n",
    "        if len(kargs) == 0 and len(args) == 0:\n",
    "            cmd = \"torch.hub.load('{}', '{}')\".format(repo, entrypoint)\n",
    "        elif len(args) != 0:\n",
    "            cmd = \"torch.hub.load('{}', '{}', {})\".format(repo, entrypoint, \", \".join(args))\n",
    "        elif len(kargs) != 0:\n",
    "            params = []\n",
    "            for k, v in kargs.items():\n",
    "                params.append(\"{}={}\".format(k, v))\n",
    "            cmd = \"torch.hub.load('{}', '{}', {})\".format(repo, entrypoint, \", \".join(params))  # , pretrained=True\n",
    "        print(cmd)\n",
    "        try: \n",
    "            a = eval(cmd)\n",
    "            module_info[\"{}___{}___{}\".format(module, repo, entrypoint)] = str(a)\n",
    "            time.sleep(1)\n",
    "            for ckpt in os.listdir(ckpt_dir):\n",
    "                shutil.move(\n",
    "                    os.path.join(ckpt_dir, ckpt),\n",
    "                    os.path.join(dir, \"{}__{}\".format(entrypoint, ckpt))\n",
    "                )\n",
    "        except:\n",
    "            with open(failed_file_path, \"a\") as ffp:\n",
    "                ffp.write(\"{}\\n\".format(module))\n",
    "\n",
    "    def find_repo_from_items(items):\n",
    "        for item in items:\n",
    "            if len(item.split(\"/\")) == 2:\n",
    "                return items.index(item)\n",
    "\n",
    "    file_dir = FILE_DIR\n",
    "\n",
    "    for module in os.listdir(file_dir):\n",
    "        if module == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "\n",
    "        module_dir = os.path.join(file_dir, module)\n",
    "        html_path = os.path.join(module_dir, \"webpage.html\")\n",
    "        with open(html_path, \"r\", encoding=\"utf-8\") as hp:\n",
    "            html = hp.read()\n",
    "        page_source = etree.HTML(html)\n",
    "        module_author = page_source.xpath('//p[@class=\"detail-lead\"]/text()')[0]\n",
    "        items = page_source.xpath(\"//code/span[@class='s']/text()\")\n",
    "        repo_index = find_repo_from_items(items)\n",
    "        repo = items[repo_index]\n",
    "        repo = repo.replace(\"'\", \"\").replace(\"\\\"\", \"\")\n",
    "\n",
    "        if (\"Pytorch Team\" in module_author) or (\n",
    "                \"Facebook AI\" in module_author):  ### Pytorch Team模型和Facebook AI模型：找//table/tbody/tr/td[1]\n",
    "#             continue ### COLAB\n",
    "            if module == \"ResNext WSL\":\n",
    "                eps = [\n",
    "                    \"resnext101_32x8d_wsl\",\n",
    "                    \"resnext101_32x16d_wsl\",\n",
    "                    \"resnext101_32x32d_wsl\",\n",
    "                    \"resnext101_32x48d_wsl\",\n",
    "                ]\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                        module,\n",
    "                        CKPT_DIR,\n",
    "                        os.path.join(TARGET_DIR, module),\n",
    "                        repo,\n",
    "                        ep\n",
    "                    )\n",
    "            elif module == \"ShuffleNet v2\":\n",
    "                eps = [\"shufflenet_v2_x1_0\"]\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                        module,\n",
    "                        CKPT_DIR,\n",
    "                        os.path.join(TARGET_DIR, module),\n",
    "                        repo,\n",
    "                        ep,\n",
    "                        pretrained=\"True\"\n",
    "                    )\n",
    "            else:\n",
    "                eps = page_source.xpath('//table/tbody/tr/td[1]/text()')\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                        module,\n",
    "                        CKPT_DIR,\n",
    "                        os.path.join(TARGET_DIR, module),\n",
    "                        repo,\n",
    "                        ep,\n",
    "                        pretrained=\"True\"\n",
    "                    )\n",
    "        \n",
    "        elif \"HuggingFace Team\" in module_author:  ### HuggingFace Team模型： 在module description和 requirement之间的部分，找//code[@class=\"highlighter-rouge\"]/text()\n",
    "#             continue  ### COLAB: 4\n",
    "            torch.hub.set_dir(\n",
    "                os.path.join(TARGET_DIR, module)\n",
    "            )\n",
    "            _ = re.findall('<article class=\"pytorch-article\">([\\s\\S]*)<h3 id=\"requirements\">', html)[0]  #\n",
    "            eps = etree.HTML(_).xpath('//code[@class=\"highlighter-rouge\"]/text()')\n",
    "            for ep in eps:\n",
    "                download_files(\n",
    "                    module,\n",
    "                    PYTORCH_TRANSFORMER_DIR,\n",
    "                    os.path.join(TARGET_DIR, module),\n",
    "                    repo,\n",
    "                    ep,\n",
    "                    \"'{}'\".format(\n",
    "                    \"bert-base-cased\" if module == \"BERT\" else\n",
    "                        \"transfo-xl-wt103\" if module == \"Transformer-XL\" else\n",
    "                        \"gpt2\" if module == \"GPT-2\" else\n",
    "                        \"openai-gpt\"), # when module == \"GPT\"\n",
    "                )\n",
    "                \n",
    "        else:  ### NVIDIA, FAIR HDGAN, 以及个人发布的模型，都在这里处理了。\n",
    "#             continue  ### COLAB. 6 modules.\n",
    "            eps = [items[repo_index + 1]]\n",
    "            if module == \"DCGAN on FashionGen\":\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                      module,\n",
    "                      CKPT_DIR,\n",
    "                      os.path.join(TARGET_DIR, module),\n",
    "                      repo,\n",
    "                      ep, \n",
    "                      pretrained=\"True\",\n",
    "                      useGPU=\"True\"\n",
    "                    )\n",
    "            elif module == \"Progressive Growing of GANs (PGAN)\":\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                      module,\n",
    "                      CKPT_DIR,\n",
    "                      os.path.join(TARGET_DIR, module),\n",
    "                      repo,\n",
    "                      ep, \n",
    "                      model_name=\"'celebAHQ-512'\",\n",
    "                      pretrained=\"True\", \n",
    "                      useGPU=\"True\"\n",
    "                    )\n",
    "            elif module == \"U-Net for brain MRI\":\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                      module,\n",
    "                      CKPT_DIR,\n",
    "                      os.path.join(TARGET_DIR, module),\n",
    "                      repo,\n",
    "                      ep, \n",
    "                      in_channels=\"3\", out_channels=\"1\", init_features=\"32\", pretrained=\"True\"\n",
    "                    )\n",
    "            else:\n",
    "                for ep in eps:\n",
    "                    download_files(\n",
    "                      module,\n",
    "                      CKPT_DIR,\n",
    "                      os.path.join(TARGET_DIR, module),\n",
    "                      repo,\n",
    "                      ep\n",
    "                    )\n",
    "                \n",
    "        ### these code is used to zip the files on colab. After zipping, we can download the zipped files.\n",
    "#         formalize_module_dir = module_dir.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n",
    "#         shell = \"zip -r {}.zip {}\".format(formalize_module_dir, formalize_module_dir)\n",
    "#         print(shell)\n",
    "#         os.system(shell)\n",
    "    with open(record_file_path, \"a\") as rfp:\n",
    "        json.dump(module_info, rfp, indent=4, sort_keys=True)\n",
    "\n",
    "\n",
    "download_all_of_the_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if you want to redo the download and remove the files downloaded before, you can do this: \n",
    "import os, shutil\n",
    "DATA_DIR = r\"/content/Data/\"\n",
    "TARGET_DIR = os.path.join(DATA_DIR, \"files\")\n",
    "CKPT_DIR = r\"/root/.cache/torch/checkpoints\"\n",
    "FILE_DIR = TARGET_DIR\n",
    "file_dir = FILE_DIR\n",
    "for module in os.listdir(file_dir):\n",
    "    module_dir = os.path.join(file_dir, module)\n",
    "    # print(module_dir)\n",
    "    for file in os.listdir(module_dir):\n",
    "        if file != \"webpage.html\":\n",
    "            file_path = os.path.join(module_dir, file)\n",
    "            if os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "            # print(os.path.join(module_dir, file))\n",
    "print(\"finished. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### zip the files into one .zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r /content/modules.zip /content/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### next step is to download the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some shell code:\n",
    "!rm -rf /root/.cache/torch/pytorch_transformers\n",
    "!mkdir /root/.cache/torch/pytorch_transformers\n",
    "!rm -rf /root/.cache/torch/checkpoints\n",
    "!mkdir /root/.cache/torch/checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
