## Overview

This module stochastically generates 14 in-between video frames given the start
and end frames.

It takes as input `<Tensor(tf.float32, shape=[16, 2, 64, 64, 3])>`, representing
a (fixed-size) batch of 16 time-wise concatenated start/end frames of 64x64 with
3 channels (RGB), and outputs `<Tensor(tf.float32, shape=[16, 14, 64, 64, 3])>`,
which are the 14 in-between frames. The pixel value range is \[0.0, 255.0\].

Note that the model is trained for this particular dataset. Therefore it will
only work on video frames from the dataset or someting very similar in
appearance.

#### Example use

See the Colab notebook below.

#### References

[1] Yunpeng Li, Dominik Roblek, and Marco Tagliasacchi.
[From Here to There: Video Inbetweening Using Direct 3D Convolutions](https://arxiv.org/abs/1905.10240).
arXiv preprint arXiv:1905.10240, 2019.